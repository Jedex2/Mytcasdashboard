import asyncio
from playwright.async_api import async_playwright
import pandas as pd
from datetime import datetime

class EnhancedTCASScraper:
    def __init__(self):
        self.programs_data = []
        self.base_url = "https://course.mytcas.com"

    async def search_and_collect_programs(self, page, keyword):
        """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£ - ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á"""
        programs = []
        
        try:
            print(f"\nüîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {keyword}")
            
            # ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å
            await page.goto(self.base_url, wait_until='networkidle', timeout=30000)
            await page.wait_for_timeout(2000)
            
            # ‡πÉ‡∏ä‡πâ selector ‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
            search_selectors = [
                "input[placeholder='‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢ ‡∏Ñ‡∏ì‡∏∞ ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£']",
                "input[placeholder*='‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤']",
                "input[type='search']",
                "input.search-input",
                "#search-input"
            ]
            
            search_input = None
            for selector in search_selectors:
                try:
                    search_input = await page.wait_for_selector(selector, timeout=5000)
                    if search_input:
                        print(f"  ‚úÖ ‡∏û‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {selector}")
                        break
                except:
                    continue
            
            if not search_input:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
                return []
            
            # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            await search_input.fill("")
            await page.wait_for_timeout(500)
            await search_input.fill(keyword)
            await search_input.press("Enter")
            await page.wait_for_timeout(3000)
            
            # ‡∏´‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢ selector ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö
            result_selectors = [
                ".t-programs > li",
                ".program-list li",
                ".search-results li",
                ".results li",
                "[data-testid='program-item']"
            ]
            
            results = []
            for selector in result_selectors:
                try:
                    results = await page.query_selector_all(selector)
                    if results:
                        print(f"  ‚úÖ ‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {selector} ({len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")
                        break
                except:
                    continue
            
            if not results:
                print("  ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
                return []
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏ö
            for i, li in enumerate(results):
                try:
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
                    title_full = await li.inner_text()
                    
                    # ‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå
                    link_element = await li.query_selector("a")
                    if not link_element:
                        continue
                        
                    link = await link_element.get_attribute("href")
                    full_link = link if link.startswith("http") else f"{self.base_url}{link}"
                    
                    # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å title
                    lines = [line.strip() for line in title_full.strip().splitlines() if line.strip()]
                    
                    program_name = lines[0] if len(lines) >= 1 else ""
                    faculty = lines[1].replace('‚Ä∫', ' > ') if len(lines) >= 2 else ""
                    university = lines[2] if len(lines) >= 3 else ""
                    
                    programs.append({
                        'keyword': keyword,
                        'program_name': program_name,
                        'university': university,
                        'faculty': faculty,
                        'title_full': title_full,
                        'url': full_link
                    })
                    
                    print(f"  üìå {i+1:2d}. {program_name[:40]}...")
                    
                except Exception as e:
                    print(f"  ‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà {i+1}: {str(e)}")
                    continue
            
            return programs
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ {keyword}: {str(e)}")
            return []

    async def scrape_program_details(self, page, program_info):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"""
        url = program_info['url']
        
        try:
            print(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á: {program_info['program_name'][:50]}...")
            
            # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
            await page.goto(url, wait_until='networkidle', timeout=30000)
            await page.wait_for_timeout(2000)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            data = {
                '‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô': program_info['keyword'],
                '‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': program_info['program_name'],
                '‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢': program_info['university'],
                '‡∏Ñ‡∏ì‡∏∞': program_info['faculty'],
                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
                '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
                '‡∏•‡∏¥‡∏á‡∏Å‡πå': url,
                '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢ selector ‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
            detail_selectors = {
                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': [
                    "dt:has-text('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£') + dd",
                    "td:has-text('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£') + td",
                    ".program-type",
                    "[data-field='program_type']"
                ],
                '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢': [
                    "dt:has-text('‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢') + dd",
                    "dt:has-text('‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°') + dd",
                    "td:has-text('‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢') + td",
                    ".fee-info",
                    ".tuition-fee",
                    "[data-field='fee']"
                ]
            }
            
            # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå
            for field, selectors in detail_selectors.items():
                for selector in selectors:
                    try:
                        element = await page.query_selector(selector)
                        if element:
                            text = await element.inner_text()
                            if text.strip():
                                data[field] = text.strip()
                                break
                    except:
                        continue
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡∏´‡∏≤‡∏Å‡∏°‡∏µ)
            try:
                table_rows = await page.query_selector_all("table tr")
                for row in table_rows:
                    cells = await row.query_selector_all("td, th")
                    if len(cells) >= 2:
                        header = await cells[0].inner_text()
                        value = await cells[1].inner_text()
                        
                        if "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó" in header and data['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£'] == '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•':
                            data['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£'] = value.strip()
                        elif any(word in header for word in ['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢', '‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°', '‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô']) and data['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢'] == '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•':
                            data['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢'] = value.strip()
            except:
                pass
            
            print(f"   ‚úÖ {data['‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢'][:25]} - {data['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢'][:30]}...")
            return data
            
        except Exception as e:
            print(f"   ‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
            return None

    async def run_scraping(self, keywords=None):
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£ scraping"""
        if keywords is None:
            keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå", "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå"]
        
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° Enhanced TCAS Scraper")
        print("="*70)
        print("üîß ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:")
        print("   ‚úÖ ‡πÉ‡∏ä‡πâ selector ‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á")
        print("   ‚úÖ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        print("   ‚úÖ ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á HTML ‡πÅ‡∏ó‡∏ô regex")
        print("   ‚úÖ ‡∏°‡∏µ fallback selector ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß")
        print("="*70)
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)
            context = await browser.new_context(
                locale='th-TH',
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            page = await context.new_page()
            
            try:
                all_programs = []
                
                # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                for keyword in keywords:
                    programs = await self.search_and_collect_programs(page, keyword)
                    all_programs.extend(programs)
                    await asyncio.sleep(2)
                
                if not all_programs:
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÉ‡∏î‡πÜ")
                    return 0
                
                print(f"\nüìã ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î {len(all_programs)} ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£...")
                
                # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
                for i, program_info in enumerate(all_programs, 1):
                    print(f"\n[{i:2d}/{len(all_programs)}]", end=" ")
                    
                    data = await self.scrape_program_details(page, program_info)
                    if data:
                        self.programs_data.append(data)
                    
                    # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô rate limiting
                    await asyncio.sleep(1.5)
                
            finally:
                await browser.close()
        
        return len(self.programs_data)

    def save_to_excel(self, filename='enhanced_tcas_data'):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Excel"""
        if not self.programs_data:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            return None
        
        df = pd.DataFrame(self.programs_data)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{filename}_{timestamp}.xlsx"
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Excel
        df.to_excel(filename, index=False, engine='openpyxl')
        
        print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {filename}")
        print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
        if len(df) > 0:
            print(f"\nüìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô:")
            keyword_counts = df['‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô'].value_counts()
            for keyword, count in keyword_counts.items():
                emoji = "ü§ñ" if "‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå" in keyword else "üíª"
                print(f"   {emoji} {keyword}: {count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
            # ‡∏ô‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢
            with_fee = len(df[df['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢'] != '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'])
            print(f"\nüí∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢: {with_fee}/{len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            print(f"\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
            for i, row in df.head(3).iterrows():
                print(f"   {i+1}. {row['‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£'][:40]}...")
                print(f"      üè´ {row['‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢']}")
                print(f"      üí∞ {row['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢']}")
        
        return df

    def save_to_csv(self, filename='enhanced_tcas_data'):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV ‡∏™‡∏≥‡∏£‡∏≠‡∏á"""
        if not self.programs_data:
            return None
        
        df = pd.DataFrame(self.programs_data)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{filename}_{timestamp}.csv"
        
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV ‡∏™‡∏≥‡∏£‡∏≠‡∏á: {filename}")
        return df

async def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üéØ Enhanced TCAS Scraper")
    print("üìö ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤")
    print("="*50)
    
    # ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    print("üîç ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:")
    print("1. ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå")
    print("2. ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå")
    print("3. ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏Ñ‡∏≥")
    print("4. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á")
    
    choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1-4): ").strip()
    
    keywords = []
    if choice == "1":
        keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå"]
    elif choice == "2":
        keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå"]
    elif choice == "3":
        keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå", "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå"]
    elif choice == "4":
        custom_keywords = input("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ): ")
        keywords = [k.strip() for k in custom_keywords.split(',') if k.strip()]
    else:
        keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå"]
    
    print(f"üéØ ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {', '.join(keywords)}")
    print("="*50)
    
    scraper = EnhancedTCASScraper()
    
    try:
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ scraping
        found_count = await scraper.run_scraping(keywords)
        
        if found_count > 0:
            print(f"\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ {found_count} ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df = scraper.save_to_excel()
            scraper.save_to_csv()  # ‡∏™‡∏≥‡∏£‡∏≠‡∏á
            
            print("\n‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            
            if df is not None and len(df) > 0:
                print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏ß‡∏°:")
                print(f"   üìö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)}")
                print(f"   üè´ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢: {df['‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢'].nunique()}")
                print(f"   üí∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢: {len(df[df['‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢'] != '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'])}")
        else:
            print("\n‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ")
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        import traceback
        print(f"üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {traceback.format_exc()}")

if __name__ == "__main__":
    asyncio.run(main())